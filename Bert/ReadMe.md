# BERT
<p>BERT(Bidirectional Encoder Representations from Transformers) is a large scaled model that has transformers inside it. Find the paper related to BERT <a href = "https://arxiv.org/pdf/1810.04805.pdf">here </a></p>
<br>A transformer here is an advancement of RNN as it is able to parallize processing, training and inference.
<img src='https://github.com/Shreyash008/Sentiment-analysis-NLP/blob/main/Bert/images/Capture.JPG'> </img>
